 Create an EC2 instance with a root ebs volume of size 20GB.

[ec2-user@ip-172-31-19-197 ~]$ df -h
Filesystem      Size  Used Avail Use% Mounted on
devtmpfs        474M     0  474M   0% /dev
tmpfs           483M     0  483M   0% /dev/shm
tmpfs           483M  412K  482M   1% /run
tmpfs           483M     0  483M   0% /sys/fs/cgroup
/dev/xvda1       20G  1.6G   19G   8% /
tmpfs            97M     0   97M   0% /run/user/1000


2. Attach and mount additional ebs volume of size 40G to above created instance.

[ec2-user@ip-172-31-19-197 ~]$ df -h
Filesystem      Size  Used Avail Use% Mounted on
devtmpfs        474M     0  474M   0% /dev
tmpfs           483M     0  483M   0% /dev/shm
tmpfs           483M  412K  482M   1% /run
tmpfs           483M     0  483M   0% /sys/fs/cgroup
/dev/xvda1       20G  1.6G   19G   8% /
tmpfs            97M     0   97M   0% /run/user/1000
[ec2-user@ip-172-31-19-197 ~]$ lsblk
NAME    MAJ:MIN RM SIZE RO TYPE MOUNTPOINT
xvda    202:0    0  20G  0 disk 
`-xvda1 202:1    0  20G  0 part /
xvdf    202:80   0  40G  0 disk 

[root@ip-172-31-19-197 ~]# lsblk
NAME    MAJ:MIN RM SIZE RO TYPE MOUNTPOINT
xvda    202:0    0  20G  0 disk 
└─xvda1 202:1    0  20G  0 part /
xvdf    202:80   0  40G  0 disk 
[root@ip-172-31-19-197 ~]# file -s /dev/xvdf
/dev/xvdf: data

[root@ip-172-31-19-197 ~]# mkfs -t xfs /dev/xvdf
meta-data=/dev/xvdf              isize=512    agcount=4, agsize=2621440 blks
         =                       sectsz=512   attr=2, projid32bit=1
         =                       crc=1        finobt=1, sparse=1, rmapbt=0
         =                       reflink=1    bigtime=0 inobtcount=0
data     =                       bsize=4096   blocks=10485760, imaxpct=25
         =                       sunit=0      swidth=0 blks
naming   =version 2              bsize=4096   ascii-ci=0, ftype=1
log      =internal log           bsize=4096   blocks=5120, version=2
         =                       sectsz=512   sunit=0 blks, lazy-count=1
realtime =none                   extsz=4096   blocks=0, rtextents=0


[root@ip-172-31-19-197 ~]# file -s /dev/xvdf
/dev/xvdf: SGI XFS filesystem data (blksz 4096, inosz 512, v2 dirs)
[root@ip-172-31-19-197 ~]# mkdir -p /shalom/new-volume 
[root@ip-172-31-19-197 ~]# mount /dev/xvdf /shalom/new-volume/
[root@ip-172-31-19-197 ~]# df -h
Filesystem      Size  Used Avail Use% Mounted on
devtmpfs        474M     0  474M   0% /dev
tmpfs           483M     0  483M   0% /dev/shm
tmpfs           483M  412K  482M   1% /run
tmpfs           483M     0  483M   0% /sys/fs/cgroup
/dev/xvda1       20G  1.6G   19G   8% /
tmpfs            97M     0   97M   0% /run/user/1000
/dev/xvdf        40G  318M   40G   1% /shalom/new-volume
[root@ip-172-31-19-197 ~]# sudo cp /etc/fstab /etc/fstab.orig


[root@ip-172-31-19-197 ~]# sudo blkid
/dev/xvda1: LABEL="/" UUID="b7bb0196-d24d-41e5-8fc6-fd0638f1a194" TYPE="xfs" PARTLABEL="Linux" PARTUUID="c050029a-ffd2-4250-8c56-8b6b11557e3e"
/dev/xvdf: UUID="7c681f18-0250-43c2-aee2-711f472da543" TYPE="xfs"
[root@ip-172-31-19-197 ~]# vi /etc/fstab
[root@ip-172-31-19-197 ~]# vi /etc/fstab
[root@ip-172-31-19-197 ~]# sudo umount /shalom/new-volume
[root@ip-172-31-19-197 ~]# sudo mount -a




[root@ip-172-31-19-197 ~]# df -h
Filesystem      Size  Used Avail Use% Mounted on
devtmpfs        474M     0  474M   0% /dev
tmpfs           483M     0  483M   0% /dev/shm
tmpfs           483M  416K  482M   1% /run
tmpfs           483M     0  483M   0% /sys/fs/cgroup
/dev/xvda1       20G  1.6G   19G   8% /
tmpfs            97M     0   97M   0% /run/user/1000
/dev/xvdf        40G  318M   40G   1% /shalom/new-volume




3 Launch a new instance in a new availability zone. Take a snapshot of above ebs volume and create an encrypted volume from the snapshot and attach it to the new ec2 instance launched in the new AZ.


https://prnt.sc/ALimR4AqJO6I
https://prnt.sc/b5Z_Baegjje0
https://prnt.sc/MlNyeFAAERIh

[root@ip-172-31-13-81 ~]# df -h
Filesystem      Size  Used Avail Use% Mounted on
devtmpfs        474M     0  474M   0% /dev
tmpfs           483M     0  483M   0% /dev/shm
tmpfs           483M  468K  482M   1% /run
tmpfs           483M     0  483M   0% /sys/fs/cgroup
/dev/xvda1      8.0G  1.6G  6.5G  20% /
tmpfs            97M     0   97M   0% /run/user/1000
tmpfs            97M     0   97M   0% /run/user/0
[root@ip-172-31-13-81 ~]# lsblk
NAME    MAJ:MIN RM SIZE RO TYPE MOUNTPOINT
xvda    202:0    0   8G  0 disk 
└─xvda1 202:1    0   8G  0 part /
xvdf    202:80   0  40G  0 disk 


[root@ip-172-31-13-81 ~]# file -s /dev/xvdf
/dev/xvdf: SGI XFS filesystem data (blksz 4096, inosz 512, v2 dirs)
[root@ip-172-31-13-81 ~]# mkdir  /shalom/volume-new
mkdir: cannot create directory ‘/shalom/volume-new’: No such file or directory
[root@ip-172-31-13-81 ~]# mkdir -p  /shalom/volume-new
[root@ip-172-31-13-81 ~]# mount /dev/xvdf  /shalom/volume-new/
[root@ip-172-31-13-81 ~]# df -h
Filesystem      Size  Used Avail Use% Mounted on
devtmpfs        474M     0  474M   0% /dev
tmpfs           483M     0  483M   0% /dev/shm
tmpfs           483M  468K  482M   1% /run
tmpfs           483M     0  483M   0% /sys/fs/cgroup
/dev/xvda1      8.0G  1.6G  6.5G  20% /
tmpfs            97M     0   97M   0% /run/user/1000
tmpfs            97M     0   97M   0% /run/user/0
/dev/xvdf        40G  318M   40G   1% /shalom/volume-new




[root@ip-172-31-13-81 ~]# sudo cp /etc/fstab /etc/fstab.orig
[root@ip-172-31-13-81 ~]# sudo blkid
/dev/xvda1: LABEL="/" UUID="b7bb0196-d24d-41e5-8fc6-fd0638f1a194" TYPE="xfs" PARTLABEL="Linux" PARTUUID="c050029a-ffd2-4250-8c56-8b6b11557e3e"
/dev/xvdf: UUID="7c681f18-0250-43c2-aee2-711f472da543" TYPE="xfs"
[root@ip-172-31-13-81 ~]# vi /etc/fstab
[root@ip-172-31-13-81 ~]# sudo umount /shalom/volume-new
[root@ip-172-31-13-81 ~]# mount -a


[root@ip-172-31-13-81 ~]# df -h
Filesystem      Size  Used Avail Use% Mounted on
devtmpfs        474M     0  474M   0% /dev
tmpfs           483M     0  483M   0% /dev/shm
tmpfs           483M  472K  482M   1% /run
tmpfs           483M     0  483M   0% /sys/fs/cgroup
/dev/xvda1      8.0G  1.6G  6.5G  20% /
tmpfs            97M     0   97M   0% /run/user/1000
tmpfs            97M     0   97M   0% /run/user/0
/dev/xvdf        40G  318M   40G   1% /shalom/volume-new
[root@ip-172-31-13-81 ~]# 

5. Create an EC2 instance. Deploy httpd and a site using bootstrap script.

https://prnt.sc/iBFypMcCy026

[ec2-user@ip-172-31-46-90 ~]$ service httpd status
Redirecting to /bin/systemctl status httpd.service
● httpd.service - The Apache HTTP Server
   Loaded: loaded (/usr/lib/systemd/system/httpd.service; enabled; vendor preset: disabled)
   Active: active (running) since Sun 2023-03-05 13:23:31 UTC; 12min ago
     Docs: man:httpd.service(8)
 Main PID: 3322 (httpd)
   Status: "Total requests: 0; Idle/Busy workers 100/0;Requests/sec: 0; Bytes served/sec:   0 B/sec"
   CGroup: /system.slice/httpd.service
           ├─3322 /usr/sbin/httpd -DFOREGROUND
           ├─3324 /usr/sbin/httpd -DFOREGROUND
           ├─3325 /usr/sbin/httpd -DFOREGROUND
           ├─3326 /usr/sbin/httpd -DFOREGROUND
           ├─3327 /usr/sbin/httpd -DFOREGROUND
           └─3328 /usr/sbin/httpd -DFOREGROUND

Mar 05 13:23:31 ip-172-31-46-90.us-east-2.compute.internal systemd[1]: Starting The Apache HTTP Server...
Mar 05 13:23:31 ip-172-31-46-90.us-east-2.compute.internal systemd[1]: Started The Apache HTTP Server.
[ec2-user@ip-172-31-46-90 ~]$ 


4. Create an EFS and mount it to an EC2 instance automatically without any manual command execution.


Created two security groups like efs-source and efs-target. 

Once while creating the efs attached efs-target security group to efs. i have added inbount rule nfs with port 2049 on on it.  the same rule added in the efs-source security group too.  and efs-source security group is attached to the ec2 instance while creating.

Then while creating the is2 instance given the script as below. 

#!/bin/bash

# Install the EFS client software
sudo yum install -y amazon-efs-utils

# Mount the EFS file system
sudo mkdir /mnt/efs
sudo mount -t nfs4 -o nfsvers=4.1,rsize=1048576,wsize=1048576,hard,timeo=600,retrans=2,noresvport fs-0f1f2ffd438bb15c1.efs.us-east-2.amazonaws.com:/ /mnt/efs

# Configure the EFS mount to persist across reboots
echo "fs-0f1f2ffd438bb15c1:/ /mnt/efs efs defaults,_netdev 0 0" | sudo tee -a /etc/fstab


now the result is.  

[ec2-user@ip-172-31-2-241 ~]$ df -h
Filesystem                                          Size  Used Avail Use% Mounted on
devtmpfs                                            474M     0  474M   0% /dev
tmpfs                                               483M     0  483M   0% /dev/shm
tmpfs                                               483M  416K  482M   1% /run
tmpfs                                               483M     0  483M   0% /sys/fs/cgroup
/dev/xvda1                                          8.0G  1.6G  6.4G  20% /
tmpfs                                                97M     0   97M   0% /run/user/1000
fs-0f1f2ffd438bb15c1.efs.us-east-2.amazonaws.com:/  8.0E     0  8.0E   0% /mnt/efs
[ec2-user@ip-172-31-2-241 ~]$ 



[ec2-user@ip-172-31-2-241 ~]$ cat /etc/fstab 
#
UUID=b7bb0196-d24d-41e5-8fc6-fd0638f1a194     /           xfs    defaults,noatime  1   1
fs-0f1f2ffd438bb15c1:/ /mnt/efs efs defaults,_netdev 0 0
[ec2-user@ip-172-31-2-241 ~]$ 

the below command we get from efs. while oening the efs we have created. there will be a option to attach.  while pressing attach we can see below command to run 

sudo mount -t nfs4 -o nfsvers=4.1,rsize=1048576,wsize=1048576,hard,timeo=600,retrans=2,noresvport fs-0f1f2ffd438bb15c1.efs.us-east-2.amazonaws.com:/ /mnt/efs





